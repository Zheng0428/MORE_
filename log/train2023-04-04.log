WARNING:__main__:*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Let's use 4 GPUs!
Let's use 4 GPUs!
Let's use 4 GPUs!
Let's use 4 GPUs!
Load 22109 data from split(s) train.Load 22109 data from split(s) train.

Load 22109 data from split(s) train.Load 22109 data from split(s) train.

Load 3142 data from split(s) valid.
Load 3142 data from split(s) valid.
Load 3142 data from split(s) valid.
Load 3142 data from split(s) valid.
Traceback (most recent call last):
  File "/home/biao/MORE_/src/tasks/more.py", line 228, in <module>
Traceback (most recent call last):
  File "/home/biao/MORE_/src/tasks/more.py", line 228, in <module>
    more = MORE()
  File "/home/biao/MORE_/src/tasks/more.py", line 91, in __init__
    more = MORE()
  File "/home/biao/MORE_/src/tasks/more.py", line 91, in __init__
    self.model = MOREModel() # Have already load the MORE_decoder weights
  File "./src/tasks/more_model.py", line 34, in __init__
    self.model = MOREModel() # Have already load the MORE_decoder weights
  File "./src/tasks/more_model.py", line 34, in __init__
    self.more_decoder = GPT2LMHeadModel.from_pretrained('gpt2', num_hidden_layers = HIDDEN_LAYERS)
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2498, in from_pretrained
    self.more_decoder = GPT2LMHeadModel.from_pretrained('gpt2', num_hidden_layers = HIDDEN_LAYERS)
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2498, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
  File "./src/tasks/gpt2.py", line 1037, in __init__
    model = cls(config, *model_args, **model_kwargs)
  File "./src/tasks/gpt2.py", line 1037, in __init__
    self.transformer = GPT2Model(config)
  File "./src/tasks/gpt2.py", line 754, in __init__
    self.transformer = GPT2Model(config)
  File "./src/tasks/gpt2.py", line 754, in __init__
    self.h = nn.ModuleList([GPT2Block(config, layer_idx=i) for i in range(config.num_hidden_layers)])
  File "./src/tasks/gpt2.py", line 754, in <listcomp>
    self.h = nn.ModuleList([GPT2Block(config, layer_idx=i) for i in range(config.num_hidden_layers)])
  File "./src/tasks/gpt2.py", line 754, in <listcomp>
    self.h = nn.ModuleList([GPT2Block(config, layer_idx=i) for i in range(config.num_hidden_layers)])
      File "./src/tasks/gpt2.py", line 439, in __init__
self.h = nn.ModuleList([GPT2Block(config, layer_idx=i) for i in range(config.num_hidden_layers)])
  File "./src/tasks/gpt2.py", line 439, in __init__
    self.attn = GPT2Attention(config, feature_dim = 1, layer_idx=layer_idx)
      File "./src/tasks/gpt2.py", line 197, in __init__
self.attn = GPT2Attention(config, feature_dim = 1, layer_idx=layer_idx)
  File "./src/tasks/gpt2.py", line 197, in __init__
    self.lt_memory = LTMemory(hidden_state_size=config.hidden_state_size)
      File "/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/transformers/configuration_utils.py", line 260, in __getattribute__
self.lt_memory = LTMemory(hidden_state_size=config.hidden_state_size)
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/transformers/configuration_utils.py", line 260, in __getattribute__
    return super().__getattribute__(key)    
return super().__getattribute__(key)
AttributeError: AttributeError'GPT2Config' object has no attribute 'hidden_state_size': 
'GPT2Config' object has no attribute 'hidden_state_size'
Traceback (most recent call last):
  File "/home/biao/MORE_/src/tasks/more.py", line 228, in <module>
    more = MORE()
  File "/home/biao/MORE_/src/tasks/more.py", line 91, in __init__
    self.model = MOREModel() # Have already load the MORE_decoder weights
  File "./src/tasks/more_model.py", line 34, in __init__
    self.more_decoder = GPT2LMHeadModel.from_pretrained('gpt2', num_hidden_layers = HIDDEN_LAYERS)
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2498, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
  File "./src/tasks/gpt2.py", line 1037, in __init__
    self.transformer = GPT2Model(config)
  File "./src/tasks/gpt2.py", line 754, in __init__
    self.h = nn.ModuleList([GPT2Block(config, layer_idx=i) for i in range(config.num_hidden_layers)])
  File "./src/tasks/gpt2.py", line 754, in <listcomp>
    self.h = nn.ModuleList([GPT2Block(config, layer_idx=i) for i in range(config.num_hidden_layers)])
  File "./src/tasks/gpt2.py", line 439, in __init__
    self.attn = GPT2Attention(config, feature_dim = 1, layer_idx=layer_idx)
  File "./src/tasks/gpt2.py", line 197, in __init__
    self.lt_memory = LTMemory(hidden_state_size=config.hidden_state_size)
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/transformers/configuration_utils.py", line 260, in __getattribute__
    return super().__getattribute__(key)
AttributeError: 'GPT2Config' object has no attribute 'hidden_state_size'
Traceback (most recent call last):
  File "/home/biao/MORE_/src/tasks/more.py", line 228, in <module>
    more = MORE()
  File "/home/biao/MORE_/src/tasks/more.py", line 91, in __init__
    self.model = MOREModel() # Have already load the MORE_decoder weights
  File "./src/tasks/more_model.py", line 34, in __init__
    self.more_decoder = GPT2LMHeadModel.from_pretrained('gpt2', num_hidden_layers = HIDDEN_LAYERS)
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2498, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
  File "./src/tasks/gpt2.py", line 1037, in __init__
    self.transformer = GPT2Model(config)
  File "./src/tasks/gpt2.py", line 754, in __init__
    self.h = nn.ModuleList([GPT2Block(config, layer_idx=i) for i in range(config.num_hidden_layers)])
  File "./src/tasks/gpt2.py", line 754, in <listcomp>
    self.h = nn.ModuleList([GPT2Block(config, layer_idx=i) for i in range(config.num_hidden_layers)])
  File "./src/tasks/gpt2.py", line 439, in __init__
    self.attn = GPT2Attention(config, feature_dim = 1, layer_idx=layer_idx)
  File "./src/tasks/gpt2.py", line 197, in __init__
    self.lt_memory = LTMemory(hidden_state_size=config.hidden_state_size)
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/transformers/configuration_utils.py", line 260, in __getattribute__
    return super().__getattribute__(key)
AttributeError: 'GPT2Config' object has no attribute 'hidden_state_size'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 240889) of binary: /home/biao/miniconda3/envs/MORE/bin/python
/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py:367: UserWarning: 

**********************************************************************
               CHILD PROCESS FAILED WITH NO ERROR_FILE                
**********************************************************************
CHILD PROCESS FAILED WITH NO ERROR_FILE
Child process 240889 (local_rank 0) FAILED (exitcode 1)
Error msg: Process failed with exitcode 1
Without writing an error file to <N/A>.
While this DOES NOT affect the correctness of your application,
no trace information about the error will be available for inspection.
Consider decorating your top level entrypoint function with
torch.distributed.elastic.multiprocessing.errors.record. Example:

  from torch.distributed.elastic.multiprocessing.errors import record

  @record
  def trainer_main(args):
     # do train
**********************************************************************
  warnings.warn(_no_error_file_warning_msg(rank, failure))
Traceback (most recent call last):
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/runpy.py", line 192, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/torch/distributed/run.py", line 702, in <module>
    main()
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 361, in wrapper
    return f(*args, **kwargs)
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/torch/distributed/run.py", line 698, in main
    run(args)
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/torch/distributed/run.py", line 689, in run
    elastic_launch(
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 116, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/biao/miniconda3/envs/MORE/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 244, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
*********************************************
  /home/biao/MORE_/src/tasks/more.py FAILED  
=============================================
Root Cause:
[0]:
  time: 2023-04-04_19:32:29
  rank: 0 (local_rank: 0)
  exitcode: 1 (pid: 240889)
  error_file: <N/A>
  msg: "Process failed with exitcode 1"
=============================================
Other Failures:
[1]:
  time: 2023-04-04_19:32:29
  rank: 1 (local_rank: 1)
  exitcode: 1 (pid: 240891)
  error_file: <N/A>
  msg: "Process failed with exitcode 1"
[2]:
  time: 2023-04-04_19:32:29
  rank: 2 (local_rank: 2)
  exitcode: 1 (pid: 240892)
  error_file: <N/A>
  msg: "Process failed with exitcode 1"
[3]:
  time: 2023-04-04_19:32:29
  rank: 3 (local_rank: 3)
  exitcode: 1 (pid: 240894)
  error_file: <N/A>
  msg: "Process failed with exitcode 1"
*********************************************

